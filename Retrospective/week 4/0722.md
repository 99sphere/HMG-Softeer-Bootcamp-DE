# 07.22 (Week 4, Day 1)
## Review
### Done
- week 3, mission 2-b 정상적으로 동작하도록 수정

### Team Review
- 리뷰
    - 주제를 정하려고 노력했지만, 잘 떠오르지 않는다. 어떤 주제가 사이드 프로젝트로 적합하고, 실현 가능하고, 빅데이터를 이영하고, 금전적인 가치가 있는지 모든 요소를 고려하는 것이 너무 어렵다.
    - Spark에 대한 기본 개념을 숙지하는 시간을 가졌습니다.
    - hadoop의 cluster ID라는 것을 알게 되었습니다.
- Keep Problem Try
    - Keep
        - 결과는 나오지 않았지만, 주제 선정을 위해 열심히 노력했습니다.
    - Problem
        - 창의성이 부족하다.
        - 데이터를 모으고 살펴봐야 insight를 찾을 수 있는데, insight를 찾아야 주제가 정해지고, 주제가 정해져야 데이터를 모을 수 있다.
    - Try
        - TLC trip record 데이터셋을 사용하기로 결정했으니, 데이터 EDA를 통해 구체적인 주제 방향성을 정하고, 빠르게 피드백을 받도록 한다.

### KPT & etc
- 계속 잡고 있던 문제를 해결했다. week3, mission 2-b에서 새로운 config로 수정한 후 namenode, datanode를 다시 켜게 되면, resource manager에는 분명히 datanode가 2개 떠있는데, namenode(localhost:9870)에서 확인하면 datanode가 잡히지 않았다.
- 최종적으로 찾은 해결책은, config를 바꾼 후 datanode를 다시 켜기 전에 (dfs.datanode.data.dir 설정에 해당하는) 기존의 data dir을 삭제해 주는 것이다.
- 새로운 config로 시작하는 namenode는 새로운 cluster ID를 갖게 되고, datanode와 namenode의 cluster id가 달라 통신이 되지 않는 것이라고 이해했다.
- 실제로 cluster id 정보가 data dir 내부 파일(datanode/current/VERSION)에 저장되어 있다.
- 그 후에 datanode를 실행하게 되면, 정상적으로 동작한다.


### To DO (07.23)
- TLC trip record 데이터셋 훑어보기
- week 4 mission 1 시작하기