# 08.22 (Week 8, Day 4)
## Review
- spark-job 수정
    - 댓글 수 max limit 200 적용
    - impact 결과 rounding
    - test 환경에서만 사용해야 했던 logic 제거
    - RedShift에서 모델 읽어왔을 때, 0으로 나눠지는 error 생기는 지 확인
    - crawler에서 받아올 정보 (sns id) 반영
    - serverless EMR이면, spark executor memory, core도 고려 안해도 되나?
- DB
    - 최소 권한 원칙을 고려하여, enduser가 이용할 RedShift 사용자 만들기. 대시보드를 그리기 위해 이용하는 table들의 읽기 권한만을 부여했다.
    - Data pipeline에서, Transform이 끝난 모든 정보를 적재한 Table을 만들었다.
        - 현재 상황에서는, 30분마다 지난 12시간의 게시물에 대한 정보를 가져오므로 같은 게시물의 정보를 24번 가져오게 된다.
        - 따라서, 대시보드에서는 각 게시물의 최신정보만을 반영하여 데이터를 시각화 할 수 있어야 한다.
        - 이를 위한 table을 따로 구성했다.
- 대시보드
    - 새롭게 구성한 Table을 이용하여 대시보드 구성.
    - 데모 영상에 어떤 내용을 넣어야 할 지 생각해보기.