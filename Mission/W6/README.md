# Week 6 
## Optimizing Spark Job
### 1. RDD over DataFrames?

### 2. Use an efficient file format and compression type

### 3. Advantages of Columnar Storage Over Row-based Storage

### 4. Apache Parquet vs Other Formats

### 5. Use SparkSQL

### 6. Shuffle in Spark

### 7. Data Shuffling is a performance killer

### 8. Causes of Shuffle

### 9. Transformation Optimization

### 10. Caching in Spark

### 11. Data Partitioning in Spark

### 12. repartition() and coalesce()

### 13. Handling Data Skews

### 14. Broadcasting

### 15. Filtering Unused Data